## 注意：

这里的设置是：输入空间与输出空间是一致的，即输入空间的词包=输出空间的词包。

Attention机制的作用是在解码时刻重点关注输入序列中的某些单词。其计算方式是利用上一时刻的隐状态与Encoder序列各个时刻的隐状态计算而得！
